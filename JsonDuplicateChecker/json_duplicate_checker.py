#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
JSONé‡å¤å­—æ®µæ£€æŸ¥å™¨
ç”¨äºæ£€æŸ¥å¤§å‹JSONæ–‡ä»¶ä¸­æŒ‡å®šå­—æ®µçš„é‡å¤å€¼
"""

import json
import sys
from collections import defaultdict, Counter
from typing import Dict, List, Any
import argparse


def find_duplicates_in_json_file(file_path: str, field_name: str) -> Dict[str, List[Dict]]:
    """
    åœ¨JSONæ–‡ä»¶ä¸­æŸ¥æ‰¾æŒ‡å®šå­—æ®µçš„é‡å¤å€¼
    
    Args:
        file_path: JSONæ–‡ä»¶è·¯å¾„
        field_name: è¦æ£€æŸ¥çš„å­—æ®µå
        
    Returns:
        åŒ…å«é‡å¤å€¼çš„å­—å…¸ï¼Œé”®ä¸ºé‡å¤çš„å­—æ®µå€¼ï¼Œå€¼ä¸ºåŒ…å«è¯¥å€¼çš„æ‰€æœ‰JSONå¯¹è±¡åˆ—è¡¨
    """
    field_values = defaultdict(list)
    duplicates = {}
    
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            # é€è¡Œè¯»å–ä»¥å¤„ç†å¤§æ–‡ä»¶
            line_number = 0
            for line in file:
                line = line.strip()
                if not line:
                    continue
                    
                line_number += 1
                try:
                    # å°è¯•è§£ææ¯è¡Œä¸ºJSONå¯¹è±¡
                    json_obj = json.loads(line)
                    
                    # æ£€æŸ¥å­—æ®µæ˜¯å¦å­˜åœ¨
                    if field_name in json_obj:
                        field_value = json_obj[field_name]
                        # å°†å­—æ®µå€¼è½¬æ¢ä¸ºå­—ç¬¦ä¸²ä»¥ä¾¿æ¯”è¾ƒ
                        field_value_str = str(field_value)
                        field_values[field_value_str].append({
                            'line_number': line_number,
                            'data': json_obj
                        })
                    else:
                        print(f"è­¦å‘Š: ç¬¬{line_number}è¡Œç¼ºå°‘å­—æ®µ '{field_name}'")
                        
                except json.JSONDecodeError as e:
                    print(f"è­¦å‘Š: ç¬¬{line_number}è¡ŒJSONè§£æé”™è¯¯: {e}")
                    continue
                    
    except FileNotFoundError:
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ '{file_path}'")
        return {}
    except Exception as e:
        print(f"é”™è¯¯: è¯»å–æ–‡ä»¶æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
        return {}
    
    # æ‰¾å‡ºé‡å¤çš„å€¼
    for field_value, records in field_values.items():
        if len(records) > 1:
            duplicates[field_value] = records
            
    return duplicates


def print_duplicate_statistics(duplicates: Dict[str, List[Dict]], field_name: str):
    """
    æ‰“å°é‡å¤å€¼çš„ç»Ÿè®¡ä¿¡æ¯
    
    Args:
        duplicates: é‡å¤å€¼å­—å…¸
        field_name: å­—æ®µå
    """
    if not duplicates:
        print(f"âœ… æ²¡æœ‰å‘ç°å­—æ®µ '{field_name}' çš„é‡å¤å€¼")
        return
    
    print(f"\nğŸ“Š é‡å¤å€¼ç»Ÿè®¡æŠ¥å‘Š")
    print(f"å­—æ®µå: {field_name}")
    print(f"å‘ç° {len(duplicates)} ä¸ªé‡å¤çš„å­—æ®µå€¼")
    
    total_duplicate_records = sum(len(records) for records in duplicates.values())
    print(f"æ€»å…±æ¶‰åŠ {total_duplicate_records} æ¡è®°å½•")
    
    print(f"\n{'='*60}")
    
    # æŒ‰é‡å¤æ¬¡æ•°æ’åº
    sorted_duplicates = sorted(duplicates.items(), key=lambda x: len(x[1]), reverse=True)
    
    for field_value, records in sorted_duplicates:
        print(f"\nğŸ”„ é‡å¤å€¼: {field_value}")
        print(f"   å‡ºç°æ¬¡æ•°: {len(records)}")
        print(f"   æ‰€åœ¨è¡Œå·: {[record['line_number'] for record in records]}")
        
        # æ˜¾ç¤ºå‰å‡ æ¡é‡å¤è®°å½•çš„è¯¦ç»†ä¿¡æ¯
        print("   é‡å¤è®°å½•è¯¦æƒ…:")
        for i, record in enumerate(records[:3]):  # åªæ˜¾ç¤ºå‰3æ¡
            print(f"     [{i+1}] è¡Œå· {record['line_number']}: {json.dumps(record['data'], ensure_ascii=False, separators=(',', ':'))}")
        
        if len(records) > 3:
            print(f"     ... è¿˜æœ‰ {len(records) - 3} æ¡è®°å½•")


def main():
    parser = argparse.ArgumentParser(description='æ£€æŸ¥JSONæ–‡ä»¶ä¸­æŒ‡å®šå­—æ®µçš„é‡å¤å€¼')
    parser.add_argument('file_path', help='JSONæ–‡ä»¶è·¯å¾„')
    parser.add_argument('field_name', help='è¦æ£€æŸ¥é‡å¤çš„å­—æ®µå')
    parser.add_argument('--output', '-o', help='è¾“å‡ºé‡å¤è®°å½•åˆ°æ–‡ä»¶')
    
    args = parser.parse_args()
    
    print(f"ğŸ” å¼€å§‹æ£€æŸ¥æ–‡ä»¶: {args.file_path}")
    print(f"ğŸ¯ æ£€æŸ¥å­—æ®µ: {args.field_name}")
    
    # æŸ¥æ‰¾é‡å¤å€¼
    duplicates = find_duplicates_in_json_file(args.file_path, args.field_name)
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print_duplicate_statistics(duplicates, args.field_name)
    
    # å¦‚æœæŒ‡å®šäº†è¾“å‡ºæ–‡ä»¶ï¼Œå°†é‡å¤è®°å½•å†™å…¥æ–‡ä»¶
    if args.output and duplicates:
        try:
            with open(args.output, 'w', encoding='utf-8') as output_file:
                output_data = {
                    'field_name': args.field_name,
                    'duplicate_count': len(duplicates),
                    'total_duplicate_records': sum(len(records) for records in duplicates.values()),
                    'duplicates': {}
                }
                
                for field_value, records in duplicates.items():
                    output_data['duplicates'][field_value] = [record['data'] for record in records]
                
                json.dump(output_data, output_file, ensure_ascii=False, indent=2)
                print(f"\nğŸ’¾ é‡å¤è®°å½•å·²ä¿å­˜åˆ°: {args.output}")
                
        except Exception as e:
            print(f"âŒ ä¿å­˜è¾“å‡ºæ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")


if __name__ == "__main__":
    main()